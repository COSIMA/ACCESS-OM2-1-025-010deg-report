{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf_index loaded.\n",
      "Available exptdata keys:  ['1deg', '025deg', '01deg']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cosima_cookbook as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "import cmocean as cm\n",
    "import pandas as pd\n",
    "\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))  # so we can import ../exptdata\n",
    "import exptdata\n",
    "print('Available exptdata keys: ', [k for k in exptdata.exptdict.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir = ''\n",
    "def savefigure(fname):\n",
    "    plt.savefig(os.path.join(figdir, fname+'.png'),dpi=300, bbox_inches=\"tight\")  # comment out to disable saving\n",
    "    #plt.savefig(os.path.join(figdir, fname+'.pdf'),dpi=300, bbox_inches=\"tight\")  # comment out to disable saving\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To deal with memory issues:\n",
    "* In a terminal on VDI (either over VNC or through SSH and inside screen/tmux), run:\n",
    "`dask-scheduler`\n",
    "* This should output the scheduler address, like `tcp://10.0.64.24:8786`. \n",
    "* Now, in another terminal (ensuring that the default conda module has cosima_cookbook installed, as all workers will need access to that), run:\n",
    "`dask-worker tcp://10.0.64.24:8786 --memory-limit 4e9 --nprocs 6 --nthreads 1 --local-directory /local/g40/amh157`\n",
    "* Then, make sure the following cell matches the scheduler address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.0.64.24:8786\n",
       "  <li><b>Dashboard: </b><a href='http://10.0.64.24:8787/status' target='_blank'>http://10.0.64.24:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>32.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.0.64.24:8786' processes=8 cores=8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client('tcp://10.0.64.24:8786', local_dir='/local/g40/amh157')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.6 s, sys: 28.6 s, total: 1min 9s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ekey='1deg'\n",
    "expt = exptdata.exptdict[ekey]['expt']\n",
    "n_files = exptdata.exptdict[ekey]['n_files']\n",
    "time_units = exptdata.exptdict[ekey]['time_units']\n",
    "offset = exptdata.exptdict[ekey]['offset']\n",
    "\n",
    "temp = cc.get_nc_variable(expt, 'ocean.nc', 'temp',\n",
    "                        chunks={'st_ocean': None}, n=n_files,\n",
    "                        time_units=time_units, offset=offset)\n",
    "\n",
    "temp_WOA13 = cc.get_nc_variable('woa13/10', 'woa13_ts_??_mom10.nc', 'temp').mean('time')\n",
    "# hacky renaming of variables so we can use as a dask array -- there's probably an elegant way to do this\n",
    "temp_WOA13 = temp_WOA13.rename({'GRID_Y_T': 'yt_ocean', 'GRID_X_T': 'xt_ocean', 'ZT': 'st_ocean'})\n",
    "temp_WOA13['st_ocean'] = temp.st_ocean\n",
    "temp_WOA13['xt_ocean'] = temp.xt_ocean\n",
    "temp_WOA13['yt_ocean'] = temp.yt_ocean\n",
    "temp_WOA13 = temp_WOA13.astype(np.float32)\n",
    "\n",
    "temp_anom = temp - temp_WOA13 - 273.15\n",
    "\n",
    "area_t = cc.get_nc_variable(expt,'ocean_grid.nc','area_t',n=1)\n",
    "mask = temp.isel(time=0).copy()\n",
    "mask = mask/mask                 ## This seems pretty dodgy to me, but it works!!\n",
    "area = mask*area_t\n",
    "area_sum = area.sum(['yt_ocean', 'xt_ocean']).load()\n",
    "\n",
    "var =area_t*temp_anom\n",
    "temp_hov = var.sum(['yt_ocean', 'xt_ocean']).load()\n",
    "temp_hov_1deg = temp_hov/area_sum\n",
    "\n",
    "IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 50s, sys: 30.4 s, total: 2min 21s\n",
      "Wall time: 5min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ekey='025deg'\n",
    "expt = exptdata.exptdict[ekey]['expt']\n",
    "n_files = exptdata.exptdict[ekey]['n_files']\n",
    "time_units = exptdata.exptdict[ekey]['time_units']\n",
    "offset = exptdata.exptdict[ekey]['offset']\n",
    "temp = cc.get_nc_variable(expt, 'ocean.nc', 'temp', n=n_files,\n",
    "                        time_units=time_units, offset=offset)\n",
    "temp_WOA13 = cc.get_nc_variable('woa13/025_KDS50', 'woa13_ts_??_mom025.nc', 'temp').mean('time')\n",
    "# hacky renaming of variables so we can use as a dask array -- there's probably an elegant way to do this\n",
    "temp_WOA13 = temp_WOA13.rename({'GRID_Y_T': 'yt_ocean', 'GRID_X_T': 'xt_ocean', 'ZT': 'st_ocean'})\n",
    "temp_WOA13['st_ocean'] = temp.st_ocean\n",
    "temp_WOA13['xt_ocean'] = temp.xt_ocean\n",
    "temp_WOA13['yt_ocean'] = temp.yt_ocean\n",
    "\n",
    "temp_WOA13 = temp_WOA13.astype(np.float32)\n",
    "\n",
    "temp_anom = temp - temp_WOA13 - 273.15\n",
    "\n",
    "area_t = cc.get_nc_variable(expt,'ocean_grid.nc','area_t',n=1)\n",
    "mask = temp.isel(time=0).copy()\n",
    "mask = mask/mask                 ## This seems pretty dodgy to me, but it works!!\n",
    "area = mask*area_t\n",
    "area_sum = area.sum(['yt_ocean', 'xt_ocean']).load()\n",
    "\n",
    "var =area_t*temp_anom\n",
    "temp_hov = var.sum(['yt_ocean', 'xt_ocean']).load()\n",
    "temp_hov_025deg = temp_hov/area_sum\n",
    "\n",
    "IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using database sqlite:////g/data3/hh5/tmp/cosima/cosima-cookbook/cosima-cookbook.db\n",
      "CPU times: user 16.8 s, sys: 8.01 s, total: 24.8 s\n",
      "Wall time: 35.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ekey='01deg'\n",
    "chunks={'xt_ocean': 400, 'yt_ocean': 300}\n",
    "\n",
    "expt = exptdata.exptdict[ekey]['expt']\n",
    "n_files = exptdata.exptdict[ekey]['n_files']\n",
    "time_units = exptdata.exptdict[ekey]['time_units']\n",
    "offset = exptdata.exptdict[ekey]['offset']\n",
    "\n",
    "temp = cc.get_nc_variable(expt, 'ocean.nc', 'temp',chunks=chunks,n=190,\n",
    "                        time_units=time_units, offset=offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using database sqlite:////g/data3/hh5/tmp/cosima/cosima-cookbook/cosima-cookbook.db\n",
      "CPU times: user 27.7 s, sys: 9.63 s, total: 37.3 s\n",
      "Wall time: 19min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "temp_WOA13 = cc.get_nc_variable('woa13/01', 'woa13_ts_??_mom01.nc', 'temp').mean('time')\n",
    "# hacky renaming of variables so we can use as a dask array -- there's probably an elegant way to do this\n",
    "temp_WOA13 = temp_WOA13.rename({'GRID_Y_T': 'yt_ocean', 'GRID_X_T': 'xt_ocean', 'ZT': 'st_ocean'})\n",
    "temp_WOA13['st_ocean'] = temp.st_ocean\n",
    "temp_WOA13['xt_ocean'] = temp.xt_ocean\n",
    "temp_WOA13['yt_ocean'] = temp.yt_ocean\n",
    "\n",
    "# force calculation and save to disk -- we could probably skip the .load() and write directly\n",
    "temp_WOA13.to_netcdf('/local/g40/amh157/woa13.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61 ms, sys: 6 ms, total: 67 ms\n",
      "Wall time: 74.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# rechunk to match ocean.nc data\n",
    "temp_WOA13 = xr.open_dataset('/local/g40/amh157/woa13.nc', chunks=chunks).temp\n",
    "temp_WOA13 = temp_WOA13.astype(np.float32)\n",
    "\n",
    "temp_anom = temp - temp_WOA13 - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using database sqlite:////g/data3/hh5/tmp/cosima/cosima-cookbook/cosima-cookbook.db\n",
      "CPU times: user 14 s, sys: 11.5 s, total: 25.5 s\n",
      "Wall time: 35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "area_t = cc.get_nc_variable(expt,'ocean_grid.nc','area_t',n=1,chunks=chunks)\n",
    "mask = temp.isel(time=0).copy()\n",
    "mask = mask/mask                 ## This seems pretty dodgy to me, but it works!!\n",
    "area = mask*area_t\n",
    "area_sum = area.sum(['yt_ocean', 'xt_ocean']).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.44 s, sys: 79 ms, total: 5.52 s\n",
      "Wall time: 5.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "var =area_t*temp_anom\n",
    "temp_hov = var.sum(['yt_ocean', 'xt_ocean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "temp_hov_01deg = temp_hov/area_sum\n",
    "temp_hov_01deg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#temp_hov.to_netcdf('/local/g40/amh157/temp_hov.nc')\n",
    "temp_hov_01deg.to_netcdf('/local/g40/amh157/temp_hov_01deg.nc')\n",
    "#temp_hov_01deg = xr.open_dataset('/local/g40/amh157/temp_hov_01deg.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,3,sharex=True,figsize=(14,6))\n",
    "plt.subplots_adjust(hspace=0)\n",
    "levs = np.arange(-1.5,1.5,0.1)\n",
    "\n",
    "# 1deg\n",
    "t_up = temp_hov_1deg.sel(st_ocean=slice(0,1000))\n",
    "t_lo = temp_hov_1deg.sel(st_ocean=slice(1000,6000))\n",
    "\n",
    "axx=ax[0,0]\n",
    "t_up.T.plot.contourf(ax=axx,levels=levs,cmap = cm.cm.balance,yincrease=False,add_colorbar=False)\n",
    "axx.set_ylabel('')\n",
    "axx.set_title('(a) ACCESS-OM2')\n",
    "axx=ax[1,0]\n",
    "p1=t_lo.T.plot.contourf(ax=axx,levels=levs,cmap = cm.cm.balance,yincrease=False,add_colorbar=False)\n",
    "axx.set_ylabel('Depth (m)')\n",
    "axx.set_xlabel('Year')\n",
    "\n",
    "# 025deg\n",
    "t_up = temp_hov_025deg.sel(st_ocean=slice(0,1000))\n",
    "t_lo = temp_hov_025deg.sel(st_ocean=slice(1000,6000))\n",
    "\n",
    "axx=ax[0,1]\n",
    "t_up.T.plot.contourf(ax=axx,levels=levs,cmap = cm.cm.balance,yincrease=False,add_colorbar=False)\n",
    "axx.set_ylabel('')\n",
    "axx.set_xlabel('')\n",
    "axx.set_title('(b) ACCESS-OM2-025')\n",
    "axx=ax[1,1]\n",
    "p1=t_lo.T.plot.contourf(ax=axx,levels=levs,cmap = cm.cm.balance,yincrease=False,add_colorbar=False)\n",
    "axx.set_ylabel('')\n",
    "axx.set_xlabel('Year')\n",
    "\n",
    "# 01deg\n",
    "t_up = temp_hov_01deg.sel(st_ocean=slice(0,1000))\n",
    "t_lo = temp_hov_01deg.sel(st_ocean=slice(1000,6000))\n",
    "\n",
    "axx=ax[0,2]\n",
    "t_up.T.plot.contourf(ax=axx,levels=levs,cmap = cm.cm.balance,yincrease=False,add_colorbar=False)\n",
    "axx.set_ylabel('')\n",
    "axx.set_xlabel('')\n",
    "plt.xlim([pd.datetime(1958,1,1),pd.datetime(2017,12,31)])\n",
    "axx.set_title('(c) ACCESS-OM2-01')\n",
    "axx=ax[1,2]\n",
    "p1=t_lo.T.plot.contourf(ax=axx,levels=levs,cmap = cm.cm.balance,yincrease=False,add_colorbar=False)\n",
    "axx.set_ylabel('')\n",
    "axx.set_xlabel('Year')\n",
    "plt.xlim([pd.datetime(1958,1,1),pd.datetime(2017,12,31)])\n",
    "\n",
    "ax1 = plt.axes([0.92,0.25,0.015,0.5])\n",
    "cb = plt.colorbar(p1,cax=ax1,orientation='vertical')\n",
    "ax1.xaxis.set_label_position(\"top\")\n",
    "cb.ax.set_xlabel('Â°C')\n",
    "\n",
    "savefigure('tz_hovmoller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_hov_01deg.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-18.10]",
   "language": "python",
   "name": "conda-env-analysis3-18.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
